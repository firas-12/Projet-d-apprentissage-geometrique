{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we aim to perform node **classification** using **graph embeddings**. We will extract node embeddings from the graph using two techniques: \n",
    "\n",
    "**DeepWalk** and **Node2Vec**. \n",
    "\n",
    "These embeddings will then be used as input features to train and evaluate **classification models**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from deepwalk_skipgram import deepwalk_skipgram\n",
    "from evaluate_embedding_node_classification import evaluate_embedding_node_classification \n",
    "from evaluate_embedding_node_classification_rf import evaluate_embedding_node_classification_rf\n",
    "from evaluate_embedding_node_classification_svm import evaluate_embedding_node_classification_svm\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import numpy as np\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 3327\n",
      "Number of edges: 9104\n",
      "Number of features: 3703\n",
      "Number of classes: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch_geometric\\data\\dataset.py:208: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch_geometric\\data\\dataset.py:216: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch_geometric\\datasets\\planetoid.py:93: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='data/CiteSeer', name='CiteSeer')\n",
    "data = dataset[0]\n",
    "\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Number of features: {data.num_node_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = to_networkx(data, node_attrs=['x'], to_undirected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix=nx.to_numpy_array(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 3327/3327 [00:00<00:00, 15781.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.09893435, -0.4263198 ,  0.8625401 , ..., -1.2171283 ,\n",
       "        -0.6660046 , -0.6723451 ],\n",
       "       [-0.2682902 , -0.6559411 ,  0.70598024, ..., -1.1611893 ,\n",
       "         0.07304472, -0.2867335 ],\n",
       "       [-0.16343555, -0.29298434,  0.8810016 , ..., -0.20318702,\n",
       "        -0.5131983 , -1.4762343 ],\n",
       "       ...,\n",
       "       [-0.02471617, -0.8680827 , -0.43844387, ..., -0.5989203 ,\n",
       "         0.03432708, -0.29996353],\n",
       "       [ 0.35099536, -0.6044491 ,  0.02776687, ..., -0.03767155,\n",
       "         0.02319954, -0.07565139],\n",
       "       [-0.48768967, -0.3172055 ,  0.9945586 , ..., -0.78757244,\n",
       "        -0.42890227, -0.09246605]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Node2Vec\n",
    "node2vec = Node2Vec(\n",
    "    G, dimensions=64, walk_length=20, num_walks=10, workers=4\n",
    ")\n",
    "\n",
    "# Train Node2Vec\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "# Get embeddings\n",
    "embeddings = model.wv  # Word2Vec model, embeddings accessible via model.wv\n",
    "\n",
    "embedding_matrix = np.array([model.wv[str(node)] for node in range(len(model.wv))])\n",
    "\n",
    "embedding_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we use the **Node2Vec** algorithm to generate node embeddings for our graph G. First, we initialize the Node2Vec model with parameters like embedding dimensions (64), walk length (20), number of walks per node (10), and parallel workers (4). The model is then trained using the **skip-gram** approach with a window size of 10, a minimum count of 1, and a batch size of 4. After training, we access the embeddings through the model.wv object, which stores the node embeddings.Finally, we create an embedding matrix containing all node embeddings for further analysis or classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for seed 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.01      0.02       238\n",
      "           1       0.39      0.41      0.40       531\n",
      "           2       0.66      0.67      0.67       601\n",
      "           3       0.42      0.60      0.50       631\n",
      "           4       0.63      0.68      0.65       537\n",
      "           5       0.56      0.41      0.47       457\n",
      "\n",
      "    accuracy                           0.52      2995\n",
      "   macro avg       0.55      0.46      0.45      2995\n",
      "weighted avg       0.54      0.52      0.50      2995\n",
      "\n",
      "Classification Report for seed 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.00      0.01       238\n",
      "           1       0.48      0.42      0.45       531\n",
      "           2       0.65      0.67      0.66       601\n",
      "           3       0.44      0.71      0.54       631\n",
      "           4       0.64      0.69      0.66       537\n",
      "           5       0.64      0.45      0.53       457\n",
      "\n",
      "    accuracy                           0.55      2995\n",
      "   macro avg       0.49      0.49      0.48      2995\n",
      "weighted avg       0.53      0.55      0.53      2995\n",
      "\n",
      "Classification Report for seed 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       238\n",
      "           1       0.42      0.38      0.40       531\n",
      "           2       0.63      0.69      0.66       601\n",
      "           3       0.43      0.63      0.51       631\n",
      "           4       0.70      0.67      0.68       537\n",
      "           5       0.55      0.48      0.51       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.45      0.48      0.46      2995\n",
      "weighted avg       0.50      0.53      0.51      2995\n",
      "\n",
      "Classification Report for seed 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.00      0.01       238\n",
      "           1       0.38      0.40      0.39       531\n",
      "           2       0.61      0.66      0.64       601\n",
      "           3       0.42      0.59      0.49       631\n",
      "           4       0.71      0.62      0.66       537\n",
      "           5       0.54      0.51      0.53       457\n",
      "\n",
      "    accuracy                           0.52      2995\n",
      "   macro avg       0.46      0.46      0.45      2995\n",
      "weighted avg       0.50      0.52      0.50      2995\n",
      "\n",
      "Classification Report for seed 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       238\n",
      "           1       0.43      0.41      0.42       531\n",
      "           2       0.65      0.66      0.66       601\n",
      "           3       0.43      0.64      0.52       631\n",
      "           4       0.65      0.71      0.68       537\n",
      "           5       0.53      0.42      0.47       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.45      0.47      0.46      2995\n",
      "weighted avg       0.50      0.53      0.51      2995\n",
      "\n",
      "Classification Report for seed 6:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.03      0.05       238\n",
      "           1       0.45      0.36      0.40       531\n",
      "           2       0.65      0.67      0.66       601\n",
      "           3       0.42      0.67      0.51       631\n",
      "           4       0.65      0.68      0.66       537\n",
      "           5       0.52      0.42      0.47       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.54      0.47      0.46      2995\n",
      "weighted avg       0.54      0.53      0.51      2995\n",
      "\n",
      "Classification Report for seed 7:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.01      0.02       238\n",
      "           1       0.49      0.35      0.41       531\n",
      "           2       0.67      0.64      0.65       601\n",
      "           3       0.41      0.69      0.51       631\n",
      "           4       0.66      0.69      0.68       537\n",
      "           5       0.55      0.47      0.51       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.49      0.48      0.46      2995\n",
      "weighted avg       0.52      0.53      0.51      2995\n",
      "\n",
      "Classification Report for seed 8:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       238\n",
      "           1       0.48      0.42      0.45       531\n",
      "           2       0.64      0.69      0.66       601\n",
      "           3       0.42      0.67      0.51       631\n",
      "           4       0.68      0.65      0.66       537\n",
      "           5       0.56      0.44      0.49       457\n",
      "\n",
      "    accuracy                           0.54      2995\n",
      "   macro avg       0.46      0.48      0.46      2995\n",
      "weighted avg       0.51      0.54      0.51      2995\n",
      "\n",
      "Classification Report for seed 9:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.03      0.06       238\n",
      "           1       0.43      0.47      0.45       531\n",
      "           2       0.65      0.69      0.67       601\n",
      "           3       0.43      0.58      0.49       631\n",
      "           4       0.69      0.66      0.68       537\n",
      "           5       0.49      0.42      0.45       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.55      0.48      0.47      2995\n",
      "weighted avg       0.54      0.53      0.51      2995\n",
      "\n",
      "Classification Report for seed 10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       238\n",
      "           1       0.41      0.41      0.41       531\n",
      "           2       0.55      0.70      0.62       601\n",
      "           3       0.47      0.64      0.54       631\n",
      "           4       0.70      0.66      0.68       537\n",
      "           5       0.57      0.41      0.48       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.45      0.47      0.45      2995\n",
      "weighted avg       0.50      0.53      0.51      2995\n",
      "\n",
      "\n",
      "Average F1 Scores across all repeats:\n",
      "Micro F1: 0.5310 ± 0.0085\n",
      "Macro F1: 0.4603 ± 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "R, S = evaluate_embedding_node_classification(embedding_matrix, data.y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for SVM (seed 1):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.01      0.02       238\n",
      "           1       0.36      0.46      0.40       531\n",
      "           2       0.67      0.66      0.66       601\n",
      "           3       0.42      0.59      0.49       631\n",
      "           4       0.66      0.66      0.66       537\n",
      "           5       0.60      0.41      0.49       457\n",
      "\n",
      "    accuracy                           0.52      2995\n",
      "   macro avg       0.51      0.46      0.45      2995\n",
      "weighted avg       0.52      0.52      0.50      2995\n",
      "\n",
      "Classification Report for SVM (seed 2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.02      0.04       238\n",
      "           1       0.47      0.43      0.45       531\n",
      "           2       0.69      0.66      0.67       601\n",
      "           3       0.42      0.73      0.53       631\n",
      "           4       0.70      0.65      0.68       537\n",
      "           5       0.62      0.42      0.50       457\n",
      "\n",
      "    accuracy                           0.55      2995\n",
      "   macro avg       0.51      0.49      0.48      2995\n",
      "weighted avg       0.54      0.55      0.53      2995\n",
      "\n",
      "Classification Report for SVM (seed 3):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.00      0.01       238\n",
      "           1       0.39      0.39      0.39       531\n",
      "           2       0.62      0.67      0.64       601\n",
      "           3       0.46      0.63      0.53       631\n",
      "           4       0.71      0.64      0.67       537\n",
      "           5       0.53      0.53      0.53       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.53      0.48      0.46      2995\n",
      "weighted avg       0.54      0.53      0.51      2995\n",
      "\n",
      "Classification Report for SVM (seed 4):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.02      0.03       238\n",
      "           1       0.37      0.44      0.40       531\n",
      "           2       0.63      0.66      0.65       601\n",
      "           3       0.44      0.58      0.50       631\n",
      "           4       0.75      0.58      0.66       537\n",
      "           5       0.54      0.53      0.54       457\n",
      "\n",
      "    accuracy                           0.52      2995\n",
      "   macro avg       0.47      0.47      0.46      2995\n",
      "weighted avg       0.51      0.52      0.51      2995\n",
      "\n",
      "Classification Report for SVM (seed 5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       238\n",
      "           1       0.40      0.44      0.42       531\n",
      "           2       0.67      0.66      0.67       601\n",
      "           3       0.44      0.65      0.52       631\n",
      "           4       0.69      0.69      0.69       537\n",
      "           5       0.52      0.40      0.45       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.45      0.47      0.46      2995\n",
      "weighted avg       0.50      0.53      0.51      2995\n",
      "\n",
      "Classification Report for SVM (seed 6):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.03      0.05       238\n",
      "           1       0.39      0.42      0.41       531\n",
      "           2       0.68      0.65      0.67       601\n",
      "           3       0.44      0.66      0.53       631\n",
      "           4       0.66      0.66      0.66       537\n",
      "           5       0.52      0.41      0.46       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.52      0.47      0.46      2995\n",
      "weighted avg       0.53      0.53      0.51      2995\n",
      "\n",
      "Classification Report for SVM (seed 7):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.01      0.02       238\n",
      "           1       0.39      0.41      0.40       531\n",
      "           2       0.67      0.62      0.64       601\n",
      "           3       0.44      0.69      0.54       631\n",
      "           4       0.70      0.63      0.66       537\n",
      "           5       0.56      0.49      0.52       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.49      0.47      0.46      2995\n",
      "weighted avg       0.52      0.53      0.51      2995\n",
      "\n",
      "Classification Report for SVM (seed 8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       238\n",
      "           1       0.45      0.41      0.43       531\n",
      "           2       0.67      0.68      0.67       601\n",
      "           3       0.40      0.66      0.50       631\n",
      "           4       0.70      0.64      0.67       537\n",
      "           5       0.52      0.44      0.47       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.46      0.47      0.46      2995\n",
      "weighted avg       0.50      0.53      0.51      2995\n",
      "\n",
      "Classification Report for SVM (seed 9):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.03      0.06       238\n",
      "           1       0.39      0.50      0.44       531\n",
      "           2       0.68      0.67      0.67       601\n",
      "           3       0.43      0.56      0.49       631\n",
      "           4       0.71      0.63      0.67       537\n",
      "           5       0.51      0.46      0.48       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.51      0.48      0.47      2995\n",
      "weighted avg       0.53      0.53      0.51      2995\n",
      "\n",
      "Classification Report for SVM (seed 10):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.01      0.02       238\n",
      "           1       0.34      0.53      0.41       531\n",
      "           2       0.61      0.67      0.64       601\n",
      "           3       0.48      0.59      0.53       631\n",
      "           4       0.75      0.62      0.68       537\n",
      "           5       0.63      0.36      0.46       457\n",
      "\n",
      "    accuracy                           0.52      2995\n",
      "   macro avg       0.52      0.46      0.46      2995\n",
      "weighted avg       0.54      0.52      0.51      2995\n",
      "\n",
      "\n",
      "Average F1 Scores for SVM:\n",
      "Micro F1: 0.5278 ± 0.0073\n",
      "Macro F1: 0.4622 ± 0.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "R, S = evaluate_embedding_node_classification_svm(embedding_matrix, data.y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Random Forest (seed 1):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.14      0.22       238\n",
      "           1       0.44      0.53      0.48       531\n",
      "           2       0.64      0.65      0.65       601\n",
      "           3       0.49      0.63      0.55       631\n",
      "           4       0.68      0.72      0.70       537\n",
      "           5       0.70      0.45      0.55       457\n",
      "\n",
      "    accuracy                           0.57      2995\n",
      "   macro avg       0.58      0.52      0.53      2995\n",
      "weighted avg       0.58      0.57      0.56      2995\n",
      "\n",
      "Classification Report for Random Forest (seed 2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.05      0.09       238\n",
      "           1       0.50      0.50      0.50       531\n",
      "           2       0.65      0.67      0.66       601\n",
      "           3       0.50      0.65      0.56       631\n",
      "           4       0.66      0.74      0.70       537\n",
      "           5       0.63      0.51      0.56       457\n",
      "\n",
      "    accuracy                           0.57      2995\n",
      "   macro avg       0.53      0.52      0.51      2995\n",
      "weighted avg       0.56      0.57      0.56      2995\n",
      "\n",
      "Classification Report for Random Forest (seed 3):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.09      0.15       238\n",
      "           1       0.48      0.42      0.45       531\n",
      "           2       0.62      0.67      0.64       601\n",
      "           3       0.50      0.68      0.57       631\n",
      "           4       0.67      0.72      0.70       537\n",
      "           5       0.66      0.55      0.60       457\n",
      "\n",
      "    accuracy                           0.57      2995\n",
      "   macro avg       0.55      0.52      0.52      2995\n",
      "weighted avg       0.56      0.57      0.56      2995\n",
      "\n",
      "Classification Report for Random Forest (seed 4):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.10      0.14       238\n",
      "           1       0.42      0.41      0.41       531\n",
      "           2       0.60      0.66      0.63       601\n",
      "           3       0.49      0.64      0.55       631\n",
      "           4       0.67      0.64      0.66       537\n",
      "           5       0.60      0.50      0.55       457\n",
      "\n",
      "    accuracy                           0.54      2995\n",
      "   macro avg       0.51      0.49      0.49      2995\n",
      "weighted avg       0.53      0.54      0.53      2995\n",
      "\n",
      "Classification Report for Random Forest (seed 5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.06      0.09       238\n",
      "           1       0.53      0.46      0.49       531\n",
      "           2       0.64      0.68      0.66       601\n",
      "           3       0.52      0.67      0.59       631\n",
      "           4       0.66      0.75      0.70       537\n",
      "           5       0.59      0.55      0.57       457\n",
      "\n",
      "    accuracy                           0.58      2995\n",
      "   macro avg       0.53      0.53      0.52      2995\n",
      "weighted avg       0.56      0.58      0.56      2995\n",
      "\n",
      "Classification Report for Random Forest (seed 6):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.13      0.20       238\n",
      "           1       0.51      0.48      0.50       531\n",
      "           2       0.63      0.71      0.67       601\n",
      "           3       0.50      0.66      0.57       631\n",
      "           4       0.65      0.69      0.67       537\n",
      "           5       0.65      0.49      0.56       457\n",
      "\n",
      "    accuracy                           0.58      2995\n",
      "   macro avg       0.55      0.53      0.53      2995\n",
      "weighted avg       0.57      0.58      0.56      2995\n",
      "\n",
      "Classification Report for Random Forest (seed 7):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.08      0.13       238\n",
      "           1       0.47      0.38      0.42       531\n",
      "           2       0.65      0.63      0.64       601\n",
      "           3       0.45      0.70      0.55       631\n",
      "           4       0.66      0.69      0.67       537\n",
      "           5       0.64      0.54      0.59       457\n",
      "\n",
      "    accuracy                           0.55      2995\n",
      "   macro avg       0.54      0.50      0.50      2995\n",
      "weighted avg       0.56      0.55      0.54      2995\n",
      "\n",
      "Classification Report for Random Forest (seed 8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.10      0.15       238\n",
      "           1       0.45      0.47      0.46       531\n",
      "           2       0.67      0.66      0.66       601\n",
      "           3       0.47      0.64      0.54       631\n",
      "           4       0.66      0.67      0.66       537\n",
      "           5       0.60      0.48      0.54       457\n",
      "\n",
      "    accuracy                           0.55      2995\n",
      "   macro avg       0.53      0.50      0.50      2995\n",
      "weighted avg       0.55      0.55      0.54      2995\n",
      "\n",
      "Classification Report for Random Forest (seed 9):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.11      0.17       238\n",
      "           1       0.45      0.56      0.50       531\n",
      "           2       0.63      0.68      0.65       601\n",
      "           3       0.49      0.59      0.54       631\n",
      "           4       0.73      0.68      0.71       537\n",
      "           5       0.63      0.51      0.56       457\n",
      "\n",
      "    accuracy                           0.57      2995\n",
      "   macro avg       0.57      0.52      0.52      2995\n",
      "weighted avg       0.57      0.57      0.56      2995\n",
      "\n",
      "Classification Report for Random Forest (seed 10):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.11      0.16       238\n",
      "           1       0.42      0.48      0.45       531\n",
      "           2       0.54      0.73      0.62       601\n",
      "           3       0.57      0.60      0.59       631\n",
      "           4       0.68      0.69      0.69       537\n",
      "           5       0.67      0.46      0.54       457\n",
      "\n",
      "    accuracy                           0.56      2995\n",
      "   macro avg       0.54      0.51      0.51      2995\n",
      "weighted avg       0.56      0.56      0.55      2995\n",
      "\n",
      "\n",
      "Average F1 Scores for Random Forest:\n",
      "Micro F1: 0.5645 ± 0.0123\n",
      "Macro F1: 0.5123 ± 0.0115\n"
     ]
    }
   ],
   "source": [
    "R, S = evaluate_embedding_node_classification_rf(embedding_matrix, data.y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepWalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.37095743  0.05554513  0.39400974 ...  0.0966529   0.14258593\n",
      "   0.41375005]\n",
      " [ 0.08652798 -0.03317666  0.20059016 ...  0.08500014  0.02109049\n",
      "   0.59266287]\n",
      " [-0.35050303 -0.59170437  0.3946816  ...  0.44476083  0.2118759\n",
      "   0.16605836]\n",
      " ...\n",
      " [-0.04889694 -0.11678085 -0.30817577 ...  0.48883709  0.4220567\n",
      "  -0.05476727]\n",
      " [ 0.3297362  -0.36138195  0.66463429 ... -0.25822192  0.22414826\n",
      "  -0.58632076]\n",
      " [ 0.05145163 -0.64699495  0.63103318 ... -0.44660971  0.08342396\n",
      "   0.74478781]]\n"
     ]
    }
   ],
   "source": [
    "embedding = deepwalk_skipgram(adj_matrix, 64, 80, 10, 8, 10, 1)\n",
    "print(embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a function **deepwalk_skipgram** that computes node embeddings for a graph using the DeepWalk algorithm with the skip-gram model. The function takes an adjacency matrix adj_matrix and several hyperparameters, including the embedding dimension, walk length, the number of random walks per node, number of workers for parallel processing, context window size, and the number of negative samples for training. It first samples random walks from the graph using the **sample_random_walks** function, converts these walks into a format compatible with Word2Vec, and then trains a Word2Vec model using the skip-gram approach. The resulting embeddings for each node are retrieved and returned as a numpy array. If a node is not present in the learned embeddings, a random vector is assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for seed 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.02      0.04       238\n",
      "           1       0.39      0.41      0.40       531\n",
      "           2       0.63      0.66      0.65       601\n",
      "           3       0.45      0.57      0.51       631\n",
      "           4       0.62      0.72      0.66       537\n",
      "           5       0.60      0.47      0.53       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.52      0.48      0.46      2995\n",
      "weighted avg       0.53      0.53      0.51      2995\n",
      "\n",
      "Classification Report for seed 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.01      0.02       238\n",
      "           1       0.41      0.51      0.46       531\n",
      "           2       0.66      0.67      0.67       601\n",
      "           3       0.47      0.57      0.51       631\n",
      "           4       0.65      0.70      0.68       537\n",
      "           5       0.59      0.49      0.54       457\n",
      "\n",
      "    accuracy                           0.55      2995\n",
      "   macro avg       0.49      0.49      0.48      2995\n",
      "weighted avg       0.52      0.55      0.53      2995\n",
      "\n",
      "Classification Report for seed 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       238\n",
      "           1       0.41      0.32      0.36       531\n",
      "           2       0.62      0.67      0.64       601\n",
      "           3       0.44      0.58      0.50       631\n",
      "           4       0.68      0.69      0.69       537\n",
      "           5       0.43      0.52      0.47       457\n",
      "\n",
      "    accuracy                           0.51      2995\n",
      "   macro avg       0.43      0.46      0.44      2995\n",
      "weighted avg       0.48      0.51      0.49      2995\n",
      "\n",
      "Classification Report for seed 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.02      0.03       238\n",
      "           1       0.40      0.45      0.42       531\n",
      "           2       0.59      0.65      0.62       601\n",
      "           3       0.45      0.60      0.52       631\n",
      "           4       0.71      0.65      0.68       537\n",
      "           5       0.58      0.47      0.52       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.48      0.47      0.46      2995\n",
      "weighted avg       0.51      0.53      0.51      2995\n",
      "\n",
      "Classification Report for seed 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.03      0.05       238\n",
      "           1       0.41      0.40      0.41       531\n",
      "           2       0.63      0.66      0.64       601\n",
      "           3       0.47      0.55      0.51       631\n",
      "           4       0.64      0.72      0.68       537\n",
      "           5       0.50      0.55      0.52       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.51      0.48      0.47      2995\n",
      "weighted avg       0.52      0.53      0.51      2995\n",
      "\n",
      "Classification Report for seed 6:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.00      0.01       238\n",
      "           1       0.40      0.38      0.39       531\n",
      "           2       0.61      0.69      0.64       601\n",
      "           3       0.45      0.64      0.53       631\n",
      "           4       0.63      0.67      0.65       537\n",
      "           5       0.63      0.47      0.54       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.47      0.47      0.46      2995\n",
      "weighted avg       0.51      0.53      0.51      2995\n",
      "\n",
      "Classification Report for seed 7:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.01      0.02       238\n",
      "           1       0.42      0.42      0.42       531\n",
      "           2       0.65      0.62      0.64       601\n",
      "           3       0.45      0.67      0.54       631\n",
      "           4       0.67      0.68      0.67       537\n",
      "           5       0.59      0.51      0.55       457\n",
      "\n",
      "    accuracy                           0.54      2995\n",
      "   macro avg       0.50      0.49      0.47      2995\n",
      "weighted avg       0.53      0.54      0.52      2995\n",
      "\n",
      "Classification Report for seed 8:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.01      0.02       238\n",
      "           1       0.42      0.40      0.41       531\n",
      "           2       0.62      0.65      0.63       601\n",
      "           3       0.42      0.64      0.51       631\n",
      "           4       0.67      0.66      0.67       537\n",
      "           5       0.60      0.49      0.54       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.52      0.48      0.46      2995\n",
      "weighted avg       0.53      0.53      0.51      2995\n",
      "\n",
      "Classification Report for seed 9:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.01      0.02       238\n",
      "           1       0.39      0.44      0.42       531\n",
      "           2       0.62      0.69      0.65       601\n",
      "           3       0.45      0.53      0.49       631\n",
      "           4       0.69      0.67      0.68       537\n",
      "           5       0.56      0.55      0.56       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.56      0.48      0.47      2995\n",
      "weighted avg       0.55      0.53      0.52      2995\n",
      "\n",
      "Classification Report for seed 10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       238\n",
      "           1       0.36      0.31      0.33       531\n",
      "           2       0.52      0.70      0.60       601\n",
      "           3       0.47      0.55      0.51       631\n",
      "           4       0.63      0.69      0.66       537\n",
      "           5       0.59      0.52      0.55       457\n",
      "\n",
      "    accuracy                           0.51      2995\n",
      "   macro avg       0.43      0.46      0.44      2995\n",
      "weighted avg       0.47      0.51      0.49      2995\n",
      "\n",
      "\n",
      "Average F1 Scores across all repeats:\n",
      "Micro F1: 0.5303 ± 0.0097\n",
      "Macro F1: 0.4624 ± 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Now, pass the embeddings to the node classification evaluation function\n",
    "R, S = evaluate_embedding_node_classification(embedding, data.y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for SVM (seed 1):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.05      0.08       238\n",
      "           1       0.36      0.47      0.41       531\n",
      "           2       0.65      0.64      0.65       601\n",
      "           3       0.44      0.61      0.51       631\n",
      "           4       0.70      0.66      0.68       537\n",
      "           5       0.70      0.46      0.56       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.54      0.48      0.48      2995\n",
      "weighted avg       0.55      0.53      0.52      2995\n",
      "\n",
      "Classification Report for SVM (seed 2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.02      0.03       238\n",
      "           1       0.37      0.58      0.45       531\n",
      "           2       0.68      0.65      0.67       601\n",
      "           3       0.46      0.55      0.50       631\n",
      "           4       0.71      0.67      0.69       537\n",
      "           5       0.65      0.43      0.52       457\n",
      "\n",
      "    accuracy                           0.54      2995\n",
      "   macro avg       0.50      0.48      0.48      2995\n",
      "weighted avg       0.54      0.54      0.52      2995\n",
      "\n",
      "Classification Report for SVM (seed 3):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       238\n",
      "           1       0.40      0.39      0.39       531\n",
      "           2       0.63      0.67      0.65       601\n",
      "           3       0.46      0.61      0.52       631\n",
      "           4       0.70      0.66      0.68       537\n",
      "           5       0.44      0.48      0.46       457\n",
      "\n",
      "    accuracy                           0.52      2995\n",
      "   macro avg       0.44      0.47      0.45      2995\n",
      "weighted avg       0.49      0.52      0.50      2995\n",
      "\n",
      "Classification Report for SVM (seed 4):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.06      0.09       238\n",
      "           1       0.39      0.42      0.40       531\n",
      "           2       0.56      0.66      0.61       601\n",
      "           3       0.46      0.58      0.52       631\n",
      "           4       0.72      0.63      0.68       537\n",
      "           5       0.58      0.46      0.51       457\n",
      "\n",
      "    accuracy                           0.52      2995\n",
      "   macro avg       0.48      0.47      0.47      2995\n",
      "weighted avg       0.51      0.52      0.51      2995\n",
      "\n",
      "Classification Report for SVM (seed 5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.03      0.05       238\n",
      "           1       0.36      0.46      0.41       531\n",
      "           2       0.67      0.64      0.65       601\n",
      "           3       0.54      0.53      0.54       631\n",
      "           4       0.66      0.71      0.69       537\n",
      "           5       0.47      0.56      0.51       457\n",
      "\n",
      "    accuracy                           0.54      2995\n",
      "   macro avg       0.51      0.49      0.47      2995\n",
      "weighted avg       0.53      0.54      0.52      2995\n",
      "\n",
      "Classification Report for SVM (seed 6):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.02      0.03       238\n",
      "           1       0.39      0.39      0.39       531\n",
      "           2       0.64      0.66      0.65       601\n",
      "           3       0.43      0.69      0.53       631\n",
      "           4       0.69      0.69      0.69       537\n",
      "           5       0.68      0.43      0.53       457\n",
      "\n",
      "    accuracy                           0.54      2995\n",
      "   macro avg       0.51      0.48      0.47      2995\n",
      "weighted avg       0.54      0.54      0.52      2995\n",
      "\n",
      "Classification Report for SVM (seed 7):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.02      0.03       238\n",
      "           1       0.41      0.40      0.41       531\n",
      "           2       0.67      0.61      0.64       601\n",
      "           3       0.43      0.73      0.54       631\n",
      "           4       0.71      0.65      0.68       537\n",
      "           5       0.60      0.45      0.51       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.51      0.48      0.47      2995\n",
      "weighted avg       0.53      0.53      0.52      2995\n",
      "\n",
      "Classification Report for SVM (seed 8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       238\n",
      "           1       0.44      0.41      0.43       531\n",
      "           2       0.65      0.66      0.65       601\n",
      "           3       0.40      0.69      0.50       631\n",
      "           4       0.71      0.65      0.68       537\n",
      "           5       0.67      0.45      0.53       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.48      0.48      0.47      2995\n",
      "weighted avg       0.52      0.53      0.52      2995\n",
      "\n",
      "Classification Report for SVM (seed 9):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.01      0.02       238\n",
      "           1       0.35      0.53      0.42       531\n",
      "           2       0.65      0.66      0.66       601\n",
      "           3       0.47      0.56      0.51       631\n",
      "           4       0.72      0.65      0.68       537\n",
      "           5       0.64      0.48      0.55       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.53      0.48      0.47      2995\n",
      "weighted avg       0.55      0.53      0.52      2995\n",
      "\n",
      "Classification Report for SVM (seed 10):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.01      0.02       238\n",
      "           1       0.35      0.39      0.37       531\n",
      "           2       0.57      0.67      0.62       601\n",
      "           3       0.50      0.58      0.54       631\n",
      "           4       0.67      0.70      0.68       537\n",
      "           5       0.58      0.49      0.53       457\n",
      "\n",
      "    accuracy                           0.53      2995\n",
      "   macro avg       0.46      0.47      0.46      2995\n",
      "weighted avg       0.50      0.53      0.51      2995\n",
      "\n",
      "\n",
      "Average F1 Scores for SVM:\n",
      "Micro F1: 0.5315 ± 0.0060\n",
      "Macro F1: 0.4687 ± 0.0080\n"
     ]
    }
   ],
   "source": [
    "# Now, pass the embeddings to the node classification evaluation function (SVM)\n",
    "R, S = evaluate_embedding_node_classification_svm(embedding, data.y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Random Forest (seed 1):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.14      0.21       238\n",
      "           1       0.46      0.52      0.49       531\n",
      "           2       0.63      0.66      0.64       601\n",
      "           3       0.48      0.61      0.54       631\n",
      "           4       0.68      0.73      0.70       537\n",
      "           5       0.75      0.51      0.61       457\n",
      "\n",
      "    accuracy                           0.57      2995\n",
      "   macro avg       0.57      0.53      0.53      2995\n",
      "weighted avg       0.58      0.57      0.56      2995\n",
      "\n",
      "Classification Report for Random Forest (seed 2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.09      0.14       238\n",
      "           1       0.41      0.51      0.46       531\n",
      "           2       0.70      0.65      0.68       601\n",
      "           3       0.50      0.62      0.55       631\n",
      "           4       0.72      0.73      0.72       537\n",
      "           5       0.64      0.53      0.58       457\n",
      "\n",
      "    accuracy                           0.57      2995\n",
      "   macro avg       0.55      0.52      0.52      2995\n",
      "weighted avg       0.57      0.57      0.56      2995\n",
      "\n",
      "Classification Report for Random Forest (seed 3):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.10      0.15       238\n",
      "           1       0.47      0.37      0.42       531\n",
      "           2       0.65      0.66      0.66       601\n",
      "           3       0.45      0.69      0.55       631\n",
      "           4       0.66      0.71      0.68       537\n",
      "           5       0.65      0.52      0.57       457\n",
      "\n",
      "    accuracy                           0.56      2995\n",
      "   macro avg       0.54      0.51      0.50      2995\n",
      "weighted avg       0.55      0.56      0.54      2995\n",
      "\n",
      "Classification Report for Random Forest (seed 4):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.10      0.14       238\n",
      "           1       0.41      0.45      0.43       531\n",
      "           2       0.62      0.65      0.64       601\n",
      "           3       0.50      0.61      0.55       631\n",
      "           4       0.67      0.63      0.65       537\n",
      "           5       0.56      0.50      0.53       457\n",
      "\n",
      "    accuracy                           0.54      2995\n",
      "   macro avg       0.50      0.49      0.49      2995\n",
      "weighted avg       0.53      0.54      0.53      2995\n",
      "\n",
      "Classification Report for Random Forest (seed 5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.06      0.10       238\n",
      "           1       0.48      0.55      0.51       531\n",
      "           2       0.65      0.70      0.68       601\n",
      "           3       0.57      0.59      0.58       631\n",
      "           4       0.64      0.73      0.69       537\n",
      "           5       0.59      0.55      0.57       457\n",
      "\n",
      "    accuracy                           0.58      2995\n",
      "   macro avg       0.54      0.53      0.52      2995\n",
      "weighted avg       0.57      0.58      0.57      2995\n",
      "\n",
      "Classification Report for Random Forest (seed 6):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.16      0.22       238\n",
      "           1       0.48      0.46      0.47       531\n",
      "           2       0.62      0.70      0.66       601\n",
      "           3       0.54      0.62      0.58       631\n",
      "           4       0.68      0.70      0.69       537\n",
      "           5       0.64      0.58      0.61       457\n",
      "\n",
      "    accuracy                           0.58      2995\n",
      "   macro avg       0.55      0.54      0.54      2995\n",
      "weighted avg       0.57      0.58      0.57      2995\n",
      "\n",
      "Classification Report for Random Forest (seed 7):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.09      0.15       238\n",
      "           1       0.51      0.46      0.48       531\n",
      "           2       0.65      0.65      0.65       601\n",
      "           3       0.49      0.69      0.57       631\n",
      "           4       0.63      0.68      0.65       537\n",
      "           5       0.64      0.54      0.59       457\n",
      "\n",
      "    accuracy                           0.57      2995\n",
      "   macro avg       0.55      0.52      0.51      2995\n",
      "weighted avg       0.56      0.57      0.55      2995\n",
      "\n",
      "Classification Report for Random Forest (seed 8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.11      0.16       238\n",
      "           1       0.46      0.41      0.43       531\n",
      "           2       0.66      0.66      0.66       601\n",
      "           3       0.46      0.68      0.55       631\n",
      "           4       0.73      0.65      0.68       537\n",
      "           5       0.56      0.53      0.54       457\n",
      "\n",
      "    accuracy                           0.55      2995\n",
      "   macro avg       0.53      0.50      0.50      2995\n",
      "weighted avg       0.55      0.55      0.54      2995\n",
      "\n",
      "Classification Report for Random Forest (seed 9):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.11      0.19       238\n",
      "           1       0.47      0.53      0.50       531\n",
      "           2       0.65      0.70      0.67       601\n",
      "           3       0.52      0.64      0.57       631\n",
      "           4       0.69      0.71      0.70       537\n",
      "           5       0.65      0.52      0.57       457\n",
      "\n",
      "    accuracy                           0.58      2995\n",
      "   macro avg       0.58      0.54      0.53      2995\n",
      "weighted avg       0.59      0.58      0.57      2995\n",
      "\n",
      "Classification Report for Random Forest (seed 10):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.11      0.17       238\n",
      "           1       0.40      0.42      0.41       531\n",
      "           2       0.57      0.72      0.64       601\n",
      "           3       0.55      0.60      0.57       631\n",
      "           4       0.68      0.70      0.69       537\n",
      "           5       0.64      0.51      0.57       457\n",
      "\n",
      "    accuracy                           0.56      2995\n",
      "   macro avg       0.53      0.51      0.51      2995\n",
      "weighted avg       0.55      0.56      0.54      2995\n",
      "\n",
      "\n",
      "Average F1 Scores for Random Forest:\n",
      "Micro F1: 0.5659 ± 0.0144\n",
      "Macro F1: 0.5161 ± 0.0147\n"
     ]
    }
   ],
   "source": [
    "# Now, pass the embeddings to the node classification evaluation function (RandomForest)\n",
    "R, S = evaluate_embedding_node_classification_rf(embedding, data.y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Node2Vec** and **DeepWalk** are both algorithms used to generate **node embeddings** for graphs, but they differ in how they sample random walks and capture node relationships:\n",
    "\n",
    "**DeepWalk** is simpler and faster, focusing mainly on local neighborhood information, while **Node2Vec** offers a more sophisticated, tunable method that can capture both local and global graph structures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
