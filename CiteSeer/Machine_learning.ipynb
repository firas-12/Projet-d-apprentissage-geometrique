{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will extract topological features from the Citeseer graph dataset and use them to train classification models, including Random Forest, Logistic Regression, and SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 3327\n",
      "Number of edges: 9104\n",
      "Number of features: 3703\n",
      "Number of classes: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch_geometric\\datasets\\planetoid.py:93: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid # type: ignore\n",
    "\n",
    "dataset = Planetoid(root='data/CiteSeer', name='CiteSeer')\n",
    "data = dataset[0]\n",
    "\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Number of features: {data.num_node_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x1345e5977c0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = to_networkx(data, node_attrs=['x'], to_undirected=True)\n",
    "G\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(index= range(3327))\n",
    "df['degree'] = [nx.degree_centrality(G) [i] for i in range(3327)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['eigenvector'] = [nx.eigenvector_centrality(G)[i] for i in range(3327)] \n",
    "list=[]\n",
    "for i in range(3327):\n",
    "    list.append(nx.eigenvector_centrality(G)[i])\n",
    "    \n",
    "df[\"eigenvector\"]=list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictt=nx.closeness_centrality(G)\n",
    "list=[]\n",
    "for i in range(3327):\n",
    "    list.append(dictt[i])\n",
    "    \n",
    "df[\"closeness\"]=list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictt=nx.betweenness_centrality(G)\n",
    "\n",
    "list=[]\n",
    "for i in range(3327):\n",
    "    list.append(dictt[i])\n",
    "    \n",
    "df[\"betweenness\"]=list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degree</th>\n",
       "      <th>eigenvector</th>\n",
       "      <th>closeness</th>\n",
       "      <th>betweenness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000301</td>\n",
       "      <td>5.356771e-20</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001503</td>\n",
       "      <td>9.526895e-04</td>\n",
       "      <td>0.086969</td>\n",
       "      <td>1.411372e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000301</td>\n",
       "      <td>5.356771e-20</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000601</td>\n",
       "      <td>1.377180e-15</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>1.808490e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000301</td>\n",
       "      <td>5.356771e-20</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>0.000301</td>\n",
       "      <td>5.356771e-20</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323</th>\n",
       "      <td>0.000301</td>\n",
       "      <td>5.356771e-20</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3324</th>\n",
       "      <td>0.000902</td>\n",
       "      <td>4.106946e-03</td>\n",
       "      <td>0.079784</td>\n",
       "      <td>4.372916e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3325</th>\n",
       "      <td>0.000301</td>\n",
       "      <td>5.356771e-20</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3326</th>\n",
       "      <td>0.000301</td>\n",
       "      <td>1.034352e-07</td>\n",
       "      <td>0.068574</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3327 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        degree   eigenvector  closeness   betweenness\n",
       "0     0.000301  5.356771e-20   0.000301  0.000000e+00\n",
       "1     0.001503  9.526895e-04   0.086969  1.411372e-04\n",
       "2     0.000301  5.356771e-20   0.000301  0.000000e+00\n",
       "3     0.000601  1.377180e-15   0.000835  1.808490e-07\n",
       "4     0.000301  5.356771e-20   0.000301  0.000000e+00\n",
       "...        ...           ...        ...           ...\n",
       "3322  0.000301  5.356771e-20   0.000301  0.000000e+00\n",
       "3323  0.000301  5.356771e-20   0.000301  0.000000e+00\n",
       "3324  0.000902  4.106946e-03   0.079784  4.372916e-05\n",
       "3325  0.000301  5.356771e-20   0.000301  0.000000e+00\n",
       "3326  0.000301  1.034352e-07   0.068574  0.000000e+00\n",
       "\n",
       "[3327 rows x 4 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe contains graph centrality measures for 3327 nodes, commonly used in network analysis:\n",
    "\n",
    "degree : Normalized degree centrality, indicating the fraction of nodes a given node is directly connected to.\n",
    "\n",
    "eigenvector : Eigenvector centrality, reflecting the influence of a node based on the influence of its neighbors.\n",
    "\n",
    "closeness : Closeness centrality, showing how quickly information can spread from a node to others in the network.\n",
    "\n",
    "betweenness : Betweenness centrality, measuring the number of shortest paths passing through a node, indicating its role as a bridge.\n",
    "\n",
    "Each row corresponds to a node, with values for these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 1, 5,  ..., 3, 1, 5])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 5, ..., 3, 1, 5], dtype=int64)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "array = data.y.numpy()\n",
    "array \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df,array,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc = sc.fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=500)\n",
    "rf.fit(X_train,y_train )\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.08      0.14        49\n",
      "           1       0.26      0.45      0.33        97\n",
      "           2       0.65      0.63      0.64       147\n",
      "           3       0.40      0.41      0.41       143\n",
      "           4       0.57      0.66      0.61       115\n",
      "           5       0.46      0.27      0.34       115\n",
      "\n",
      "    accuracy                           0.46       666\n",
      "   macro avg       0.47      0.42      0.41       666\n",
      "weighted avg       0.48      0.46      0.45       666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.3213213213213213\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        49\n",
      "           1       0.00      0.00      0.00        97\n",
      "           2       0.86      0.41      0.55       147\n",
      "           3       0.26      0.45      0.33       143\n",
      "           4       0.26      0.77      0.39       115\n",
      "           5       0.00      0.00      0.00       115\n",
      "\n",
      "    accuracy                           0.32       666\n",
      "   macro avg       0.23      0.27      0.21       666\n",
      "weighted avg       0.29      0.32      0.26       666\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# SVM Classifier\n",
    "svm_model = SVC(kernel='linear', C=1, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"SVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.33183183183183185\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        49\n",
      "           1       0.00      0.00      0.00        97\n",
      "           2       0.84      0.41      0.55       147\n",
      "           3       0.28      0.52      0.36       143\n",
      "           4       0.26      0.74      0.39       115\n",
      "           5       0.00      0.00      0.00       115\n",
      "\n",
      "    accuracy                           0.33       666\n",
      "   macro avg       0.23      0.28      0.22       666\n",
      "weighted avg       0.29      0.33      0.27       666\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\21623\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, y_pred_lr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
